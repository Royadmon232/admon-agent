import { createRetrievalChain } from 'langchain/chains/retrieval';
import { createStuffDocumentsChain } from 'langchain/chains/combine_documents';
import { ChatOpenAI, OpenAIEmbeddings } from '@langchain/openai';
import { PGVectorStore } from '@langchain/community/vectorstores/pgvector';
import { PromptTemplate, ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts';
import { HumanMessage, AIMessage, SystemMessage } from '@langchain/core/messages';
import pg from 'pg';
import 'dotenv/config';
import kbConfig from '../src/insuranceKbConfig.js';
import { normalize } from '../utils/normalize.js';
import { withTimeout } from '../utils/llmTimeout.js';
import { splitQuestions } from '../utils/splitQuestions.js';
import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join, resolve } from 'path';

// Load sales templates
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const templatesPath = join(process.cwd(), 'marketing_templates.json');

console.info(`[RAG] Loading templates from: ${templatesPath}`);

let salesTemplates;
try {
  salesTemplates = JSON.parse(readFileSync(templatesPath, 'utf8'));
  console.info('[RAG] Successfully loaded marketing templates');
} catch (error) {
  console.error('[RAG] Error loading marketing templates:', error.message);
  // Fallback to default templates if file not found
  salesTemplates = {
    LEAD: [
      "×‘×™×˜×•×— ×“×™×¨×” ××’×Ÿ ×¢×œ ×”×”×©×§×¢×” ×”×›×™ ×—×©×•×‘×” ×©×œ×š ××¤× ×™ × ×–×§×™ ××™×, ×’× ×™×‘×” ×•××©",
      "×¤×•×œ×™×¡×ª ×‘×™×˜×•×— ×“×™×¨×” ××™×›×•×ª×™×ª ×™×›×•×œ×” ×œ×—×¡×•×š ×œ×š ×¢×©×¨×•×ª ××œ×¤×™ ×©×§×œ×™× ×‘×¢×ª × ×–×§"
    ],
    DEFAULT: [
      "×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š ×œ×”×‘×™×Ÿ ××ª ×”××¤×©×¨×•×™×•×ª ×”×©×•× ×•×ª ×œ×‘×™×˜×•×— ×“×™×¨×”",
      "×›×œ ××§×¨×” ×”×•× ×™×™×—×•×“×™ ×•×× ×™ ××ª××™× ××ª ×”×”××œ×¦×•×ª ×œ×¦×¨×›×™× ×©×œ×š"
    ]
  };
  console.info('[RAG] Using fallback templates');
}

console.info("âœ… PromptTemplate loaded correctly");

// Initialize PostgreSQL pool - prioritize DATABASE_URL for external connections
const pool = new pg.Pool({ 
  connectionString: process.env.DATABASE_URL,
  ssl: {
    rejectUnauthorized: false
  }
});

// Log successful connection
pool.on('connect', () => {
  console.info('âœ… LangChain DB connection established using external DATABASE_URL with SSL');
});

// Initialize OpenAI components
const embeddings = new OpenAIEmbeddings({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: 'text-embedding-3-small'
});

const llm = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: 'gpt-4o',
  temperature: 0.7
});

let vectorStore = null;
let chain = null;

/**
 * Direct search in insurance_qa table to get answers
 * @param {string} question - User question
 * @param {number} limit - Maximum number of results
 * @param {number} threshold - Similarity threshold (0-1)
 * @returns {Promise<Array>} Array of {question, answer, similarity} objects
 */
async function searchInsuranceQA(question, limit = 10, threshold = 0.65) {
  try {
    // Get embedding for the question
    const questionEmbedding = await embeddings.embedTextQuery(question);
    
    // Query the database directly with cosine similarity
    const result = await pool.query(`
      SELECT 
        question,
        answer,
        1 - (embedding <=> $1::vector) as similarity
      FROM insurance_qa
      WHERE 1 - (embedding <=> $1::vector) > $2
      ORDER BY embedding <=> $1::vector
      LIMIT $3
    `, [questionEmbedding, threshold, limit]);
    
    console.info(`[RAG] Direct DB search found ${result.rows.length} matches for: "${question}"`);
    
    return result.rows.map(row => ({
      question: row.question,
      answer: row.answer,
      similarity: row.similarity
    }));
  } catch (error) {
    console.error('[RAG] Error in direct DB search:', error);
    return [];
  }
}

// Initialize the RAG chain
export async function initializeChain() {
  try {
    // Initialize PGVector store using external DATABASE_URL
    // Note: Using pure vector similarity search without metadata filtering
    vectorStore = await PGVectorStore.initialize(
      embeddings,
      {
        postgresConnectionOptions: {
          connectionString: process.env.DATABASE_URL,
          ssl: { rejectUnauthorized: false }
        },
        tableName: kbConfig.tableName,
        columns: {
          idColumnName: kbConfig.idColumnName ?? 'id',
          vectorColumnName: kbConfig.embeddingColumnName,
        
          metadataColumnName: null // Explicitly disable metadata
        },
        filter: {}, // Force embedding-only search with empty filter
        distanceStrategy: 'cosine' // Use cosine similarity for vector comparison
      }
    );

    // Create modern prompt template with anti-hallucination
    const chatPrompt = ChatPromptTemplate.fromTemplate(`
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ.

×”× ×—×™×•×ª ×œ×˜×•×Ÿ ×•×©×¤×”:
- ×¤× ×” ×œ×œ×§×•×— ×‘×©××• ×”×¤×¨×˜×™ ×›×©×™×“×•×¢ ("{{name}}, ××©××— ×œ×”×¡×‘×™×¨...")
- ×”×©×ª××© ×‘×œ×©×•×Ÿ ×—××”, ××™×©×™×ª ×•××–××™× ×” ×ª×•×š ×©××™×¨×” ×¢×œ ××§×¦×•×¢×™×•×ª
- ×”×¤×’×Ÿ ×××¤×ª×™×” ×•×“××’×” ×›× ×” ("×× ×™ ××‘×™×Ÿ ××ª ×”×—×©×©×•×ª ×©×œ×š, ×–×” ×˜×‘×¢×™...")
- ×”×©×ª××© ×‘×‘×™×˜×•×™×™× ××¢×•×“×“×™× ×•×—×™×•×‘×™×™×
- ×¤× ×” ×œ×œ×§×•×— ×‘×’×•×£ ×©× ×™ × ×•×›×— (××ª/×”)
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™

×”× ×—×™×•×ª ×—×©×•×‘×•×ª:
- ×”×©×ª××© ××š ×•×¨×§ ×‘××™×“×¢ ×”××•×¤×™×¢ ×‘×”×§×©×¨ ×œ××˜×”
- ××œ ×ª××¦×™× ××• ×ª× ×—×© × ×ª×•× ×™× ×©××™× × ××•×¤×™×¢×™× ×‘××¤×•×¨×©
- ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢, ×××•×¨ "××‘×“×•×§ ××ª ×”× ×•×©× ×•××—×–×•×¨ ××œ×™×š"
- ××œ ×ª×¢× ×” ×¢×œ ×©××œ×•×ª ×©××™× ×Ÿ ×§×©×•×¨×•×ª ×œ×‘×™×˜×•×— ×“×™×¨×”

×”×§×©×¨ (××™×“×¢ ××”×××’×¨):
{context}

×©××œ×”: {input}

×ª×Ÿ ×ª×©×•×‘×” ××§×¦×•×¢×™×ª, ×™×“×™×“×•×ª×™×ª ×•××§×™×¤×” ×‘×¢×‘×¨×™×ª ×”××‘×•×¡×¡×ª ×¢×œ ×”××™×“×¢ ×‘×”×§×©×¨ ×‘×œ×‘×“.
×× ×”××™×“×¢ ×‘×”×§×©×¨ ×œ× ××¡×¤×™×§, ×××•×¨ ×–××ª ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª.
×‘×¡×•×£ ×”×ª×©×•×‘×”, ×× ××ª××™×, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×—××” ×•××–××™× ×”.
`);

    // Create document chain
    const documentChain = await createStuffDocumentsChain({
      llm,
      prompt: chatPrompt
    });

    // Create the conversational retrieval chain
    chain = await createRetrievalChain({
      combineDocsChain: documentChain,
      retriever: vectorStore.asRetriever({
        k: 8,
        searchType: 'similarity',
        searchKwargs: {
          scoreThreshold: 0.65
        }
      })
    });

    console.log('âœ… LangChain RAG chain initialized successfully');
  } catch (error) {
    console.error('âš ï¸ Failed to initialize LangChain RAG chain:', error.message);
    chain = null;
  }
}

// Initialize on module load
// initializeChain(); // Commented out - now called from index.js

// Ensure the vector store table has the required columns
(async () => {
  try {
    await pool.query(`
      DO $$ 
      BEGIN
        -- Add metadata column if it doesn't exist
        IF NOT EXISTS (
          SELECT 1 
          FROM information_schema.columns 
          WHERE table_name = '${kbConfig.tableName}' 
          AND column_name = 'metadata'
        ) THEN
          ALTER TABLE ${kbConfig.tableName} 
          ADD COLUMN metadata JSONB DEFAULT '{}'::jsonb;
        END IF;
      END $$;
    `);
    console.log('âœ… Vector store table structure verified');
  } catch (err) {
    console.error('âš ï¸ Failed to verify vector store table structure:', err.message);
  }
})();

// Removed local splitQuestions function - using the GPT-4o based one from utils/splitQuestions.js

/**
 * Merge answers with GPT-4o for natural, marketing-oriented Hebrew response
 * @param {Array} answerGroups - Array of {question, answers} objects
 * @param {string} originalQuestion - Original user question
 * @param {string} historyContext - Conversation history context
 * @returns {Promise<string>} Merged answer
 */
async function mergeAnswersWithGPT(answerGroups, originalQuestion, historyContext = '') {
  const systemPrompt = `××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ. ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ××§×¦×•×¢×™ ×•××“×™×‘. ×ª×¤×§×™×“×š ×œ×¢× ×•×ª ×¢×œ ×©××œ×•×ª ×‘× ×•×©× ×‘×™×˜×•×— ×“×™×¨×” ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª, ×™×“×™×“×•×ª×™×ª ×•××§×™×¤×”.

×›×œ ×ª×©×•×‘×” ×©×œ×š ×—×™×™×‘×ª:
  1. ×œ×”×™×•×ª ×‘×¢×‘×¨×™×ª ×ª×§×™× ×” ×•××§×¦×•×¢×™×ª
  2. ×œ×”×™×•×ª ×× ×•×¡×—×ª ×‘×¦×•×¨×” ×™×“×™×“×•×ª×™×ª, ××›×‘×“×ª ×•×‘×˜×•×Ÿ ××™×©×™ ×•× ×¢×™×
  3. ×œ×”×ª×™×™×—×¡ ×™×©×™×¨×•×ª ×œ×©××œ×” ×©× ×©××œ×”
  4. ×œ×›×œ×•×œ ××ª ×›×œ ×”××™×“×¢ ×”×¨×œ×•×•× ×˜×™ ×•×”×—×©×•×‘
  5. ×œ×”×™×•×ª ××“×•×™×§×ª ××‘×—×™× ×” ××§×¦×•×¢×™×ª

×§×™×‘×œ×ª ××™×“×¢ ×¨×œ×•×•× ×˜×™ ××”×××’×¨ ×©×œ× ×•. ×¢×œ×™×š:
  1. ×œ×©×œ×‘ ××ª ×”××™×“×¢ ×”×¨×œ×•×•× ×˜×™ ×‘×ª×©×•×‘×” ××—×ª ××§×™×¤×” ×•×§×•×”×¨× ×˜×™×ª
  2. ×œ× ×¡×— ×‘×¡×’× ×•×Ÿ ××™×©×™ ×•×™×™×—×•×“×™ ××©×œ×š, ×©×ª×¨×’×™×© ××•×ª× ×˜×™×ª ×•×˜×‘×¢×™×ª ×œ×œ×§×•×—
  3. ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢ ×œ×—×œ×§ ××”×©××œ×”, ×”×©×œ× ××”×™×“×¢ ×©×œ×š
  4. ×œ×•×•×“× ×©×”×ª×©×•×‘×” ×©×œ××” ×•××©×“×¨×ª ×‘×™×˜×—×•×Ÿ ×•××§×¦×•×¢×™×•×ª`;

  let contextBlock = '';
  for (const group of answerGroups) {
    if (group.answers && group.answers.length > 0) {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™:\n${group.answers.join('\n')}\n`;
    } else {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™: ××™×Ÿ ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ - ×™×© ×œ×¢× ×•×ª ××”×™×“×¢ ×”×›×œ×œ×™\n`;
    }
  }

  const userPrompt = `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n××™×“×¢ ×©× ××¦× ×‘×××’×¨:\n${contextBlock}\n\n${historyContext}\n\n×× × ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×•××§×¦×•×¢×™×ª ×œ×©××œ×ª ×”×œ×§×•×—.`;

  try {
    const response = await withTimeout(llm.invoke([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ]), 20000);
    
    return response.content.trim();
  } catch (error) {
    console.error('[LangChain] Error merging answers with GPT:', error);
    throw error;
  }
}

/**
 * Detect if a question is a follow-up to the previous conversation
 * @param {string} text - User question
 * @param {Array} history - Conversation history
 * @returns {Promise<boolean>} True if it's a follow-up question
 */
async function isFollowUpQuestion(text, history) {
  if (!history || history.length === 0) return false;
  
  // Common Hebrew follow-up patterns
  const followUpPatterns = [
    /^(×ª×•×›×œ|×™×›×•×œ|××¤×©×¨) ×œ×”×¡×‘×™×¨/i,
    /^××” (×–××ª ××•××¨×ª|×”×›×•×•× ×”)/i,
    /^(×¢×•×“|×™×•×ª×¨) (×¤×¨×˜×™×|××™×“×¢|×”×¡×‘×¨)/i,
    /^(×œ×|×›×Ÿ),? ××‘×œ/i,
    /^×•(××”|××™×š|×›××”|××ª×™|××™×¤×”|×œ××”)/i,
    /^×‘× ×•×¡×£/i,
    /^×’×/i,
    /^××–/i,
    /^×œ××”/i,
    /^××™×š ×‘×“×™×•×§/i,
    /^×ª×Ÿ ×œ×™ ×“×•×’××”/i,
    /^×”×¡×‘×¨/i,
    /^×¤×¨×˜/i
  ];
  
  // Check if the question matches follow-up patterns
  const normalized = text.trim();
  return followUpPatterns.some(pattern => pattern.test(normalized));
}

/**
 * Calculate text similarity using cosine similarity on word vectors
 * @param {string} text1 - First text
 * @param {string} text2 - Second text
 * @returns {number} Similarity score (0-1)
 */
function calculateTextSimilarity(text1, text2) {
  const words1 = normalize(text1).split(/\s+/);
  const words2 = normalize(text2).split(/\s+/);
  
  // Create frequency maps
  const freq1 = {};
  const freq2 = {};
  
  words1.forEach(word => freq1[word] = (freq1[word] || 0) + 1);
  words2.forEach(word => freq2[word] = (freq2[word] || 0) + 1);
  
  // Get all unique words
  const allWords = [...new Set([...words1, ...words2])];
  
  // Calculate dot product and magnitudes
  let dotProduct = 0;
  let magnitude1 = 0;
  let magnitude2 = 0;
  
  allWords.forEach(word => {
    const f1 = freq1[word] || 0;
    const f2 = freq2[word] || 0;
    dotProduct += f1 * f2;
    magnitude1 += f1 * f1;
    magnitude2 += f2 * f2;
  });
  
  magnitude1 = Math.sqrt(magnitude1);
  magnitude2 = Math.sqrt(magnitude2);
  
  if (magnitude1 === 0 || magnitude2 === 0) return 0;
  
  return dotProduct / (magnitude1 * magnitude2);
}

/**
 * Check if a similar question was already asked and return the previous answer
 * @param {string} question - Current question
 * @param {Array} history - Conversation history
 * @param {number} similarityThreshold - Minimum similarity to consider a match (default 0.65)
 * @returns {object|null} Previous answer if found, null otherwise
 */
function findSimilarPreviousQuestion(question, history, similarityThreshold = 0.65) {
  if (!history || history.length === 0) return null;
  
  const normalizedQuestion = normalize(question);
  
  for (let i = history.length - 1; i >= 0; i--) {
    const exchange = history[i];
    if (exchange.user) {
      const normalizedPrevQuestion = normalize(exchange.user);
      const similarity = calculateTextSimilarity(normalizedQuestion, normalizedPrevQuestion);
      
      if (similarity >= similarityThreshold) {
        console.info(`[RAG] Found similar previous question with similarity ${similarity.toFixed(2)}`);
        return {
          previousQuestion: exchange.user,
          previousAnswer: exchange.bot,
          similarity: similarity
        };
      }
    }
  }
  
  return null;
}

/**
 * Get smart answer using LangChain RAG
 * @param {string} question - User question
 * @param {Array} context - Array of conversation history objects with user/bot properties
 * @returns {Promise<string|null>} Answer or null if not available
 */
export async function smartAnswer(question, context = []) {
  console.info(`[smartAnswer] Starting analysis for: "${question}"`);
  console.info(`[smartAnswer] Context has ${context.length} previous exchanges`);

  console.debug('[RAG] Normalized question:', question);
  console.debug('[RAG] Using column:', kbConfig.embeddingColumnName);
  console.debug('[RAG] Context length:', context.length);

  // Check for greetings first - only if this is the first message
  if (context.length === 0 && /^(×”×™×™|×©×œ×•×|×¦×”×¨×™×™×|×¢×¨×‘ ×˜×•×‘)/i.test(question.trim())) {
    console.debug('[RAG] Detected greeting - returning standard response');
    return "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ××™×š ××•×›×œ ×œ×¢×–×•×¨?";
  }

  // Check if question is out of scope
  const insuranceKeywords = ['×‘×™×˜×•×—', '×¤×•×œ×™×¡×”', '×›×™×¡×•×™', '×“×™×¨×”', '× ×–×§', '×ª×‘×™×¢×”', '×¤×¨××™×”', '×”×©×ª×ª×¤×•×ª'];
  const hasInsuranceContext = insuranceKeywords.some(keyword => question.includes(keyword));

  // If the message is clearly unrelated to insurance (small-talk, chit-chat, etc.) and there is no prior context,
  // let GPT-4o answer naturally instead of refusing.
  if (!hasInsuranceContext && context.length === 0) {
    console.info('[RAG] Detected small-talk / out-of-domain question â€“ using GPT-4o friendly fallback');

    const messages = [
      new SystemMessage(`××ª×” × ×¦×™×’ ×©×™×¨×•×ª ××§×¦×•×¢×™ ×•× ×¢×™× ×©×œ ×—×‘×¨×ª ×‘×™×˜×•×—.
      ×¢×œ×™×š ×œ×¢× ×•×ª ×‘×¦×•×¨×” ×™×“×™×“×•×ª×™×ª ×•××§×¦×•×¢×™×ª ×œ×©××œ×•×ª ×›×œ×œ×™×•×ª.
      ×× ×”×©××œ×” ×œ× ×§×©×•×¨×” ×œ×‘×™×˜×•×—, ×¢× ×” ×‘×¦×•×¨×” × ×¢×™××” ×•×”×¦×’ ××ª ×¢×¦××š ×›× ×¦×™×’ ×©×™×¨×•×ª.
      ×©××•×¨ ×¢×œ ×˜×•×Ÿ ××§×¦×•×¢×™ ××š ×™×“×™×“×•×ª×™.
      ×ª××™×“ ×¡×™×™× ×‘×”×¦×¢×ª ×¢×–×¨×” ×‘× ×•×©× ×‘×™×˜×•×—.`),
      new HumanMessage(question)
    ];

    try {
      const response = await withTimeout(llm.call(messages), 20000);
      return response.content.trim();
    } catch (err) {
      console.error('[RAG] GPT-4o fallback error:', err);
      // In worst-case, still provide graceful reply
      return '×”×›×œ ××¦×•×™×Ÿ, ×ª×•×“×” ×¢×œ ×”×”×ª×¢× ×™×™× ×•×ª! ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×‘× ×•×©× ×‘×™×˜×•×— ×”×“×™×¨×”? ğŸ˜Š';
    }
  }

  try {
    // First check if this exact or similar question was already asked
    const similarPrevious = findSimilarPreviousQuestion(question, context);
    if (similarPrevious) {
      console.info('[RAG] Found similar previous question!');
      console.info(`[RAG] Previous Q: "${similarPrevious.previousQuestion}"`);
      console.info(`[RAG] Similarity: ${similarPrevious.similarity.toFixed(2)}`);
      console.info('[RAG] Reusing previous answer');
      return similarPrevious.previousAnswer;
    }
    
    // Build conversation history for prompt
    const conversationHistory = context.map(msg => `User: ${msg.user}\nBot: ${msg.bot}`).join('\n');
    
    // Check if this is a follow-up question using GPT-4o
    const contextCheckPrompt = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™.
×”×©×ª××© ×‘×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×” ×”×‘××” ×›×“×™ ×œ×§×‘×•×¢ ×× ×”×©××œ×” ×”× ×•×›×—×™×ª ×”×™× ×”××©×š ×œ×©×™×—×” ×§×•×“××ª.
×× ×”××©×ª××© ×©×•××œ ×©××œ×ª ×”××©×š (×œ××©×œ "×ª×¡×‘×™×¨ ×©×•×‘"), ×¢× ×” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×§×©×¨ ×”×§×•×“×.
×× ×”××©×ª××© ×©×•××œ ××©×”×• ×—×“×©, ×”×ª×¢×œ× ××”×§×©×¨ ×•×”×¤×¢×œ ×—×™×¤×•×© ×•×§×˜×•×¨×™ ×›×¨×’×™×œ.

×—×©×•×‘:
- ××œ ×ª×—×–×•×¨ ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×©×•×‘ ×× ×›×‘×¨ ×”×¦×’×ª ××ª ×¢×¦××š
- ×”×©×ª××© ×‘×©×¤×” ×˜×‘×¢×™×ª, ×—××” ×•××§×¦×•×¢×™×ª
- ×“×‘×¨ ×‘×’×•×£ ×¨××©×•×Ÿ
- ×¤× ×” ×œ×œ×§×•×— ×‘×©××• ×× ×™×“×•×¢
- ×”×¤×’×Ÿ ×××¤×ª×™×” ×•×“××’×”
- ×”×™×× ×¢ ××œ×•××¨ ×©××ª×” ×‘×•×˜ ××• AI

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}
`;

    // First, check if this is a follow-up question
    const isFollowUp = await isFollowUpQuestion(question, context);
    console.info(`[RAG] Is follow-up question: ${isFollowUp}`);
    
    if (isFollowUp && context.length > 0) {
      // Follow-up detected - answer directly using context only
      console.info('[RAG] Follow-up question detected, using context only');
      
      const messages = [
        { role: 'system', content: contextCheckPrompt },
        { role: 'user', content: '×¢× ×” ×¢×œ ×”×©××œ×” ×”× ×•×›×—×™×ª ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×™×¡×˜×•×¨×™×”. ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×‘×¢×‘×¨×™×ª.' }
      ].filter(m => m && typeof m === 'object' && m.content);

      const response = await withTimeout(llm.call(messages), 20000);
      
      console.debug('[RAG] Generated follow-up response');
      return response.content.trim();
    }

    // Not a clear follow-up, proceed with vector search
    console.info('[RAG] Running vector search...');
    
    // Correctly await the async splitQuestions helper
    const questions = await splitQuestions(question);
    console.info(`[RAG] Processing ${questions.length} question(s)`);

    // Process each question with timeout protection
    let answerGroups = [];
    let foundAnswers = false;
    
    for (const q of questions) {
      try {
        const query = normalize(q);
        
        // Use direct DB search to get answers
        let results = await searchInsuranceQA(query, 15, 0.65);
        
        // If no results, try with lower threshold
        if (results.length === 0) {
          console.debug('[RAG] First attempt failed, trying with lower threshold...');
          results = await searchInsuranceQA(query, 15, 0.60);
        }
        
        // If still no results, mark as no match
        if (results.length === 0) {
          console.info('[RAG] No matches found even with lower threshold');
          continue;
        }
        
        // Log results for debugging
        console.debug(`[RAG] Found ${results.length} matches for "${q}"`);
        results.forEach(r => {
          console.debug(`[RAG] Match - similarity: ${r.similarity.toFixed(4)}, Q: ${r.question.slice(0, 50)}...`);
        });
        
        // Extract answers
        const answers = results
          .map(result => {
            const cleaned = result.answer
              .replace(/×œ××™×“×¢ × ×•×¡×£ ×¦×•×¨ ×§×©×¨/g, '')
              .replace(/×œ×¤×¨×˜×™× × ×•×¡×¤×™×/g, '')
              .replace(/\s{2,}/g, ' ')
              .trim();
            
            if (cleaned.length < 20) return null; // Too short to be useful
            
            return cleaned;
          })
          .filter(answer => answer && answer.trim().length > 0);
        
        if (answers.length > 0) {
          foundAnswers = true;
          console.debug(`[RAG] Found ${answers.length} matches for question: ${q}`);
        } else {
          console.debug(`[RAG] No useful matches found for question: ${q}`);
        }
        
        answerGroups.push({
          question: q,
          answers: answers
        });
      } catch (error) {
        console.error(`[RAG] Error processing question "${q}":`, error);
        answerGroups.push({
          question: q,
          answers: []
        });
      }
    }

    // If no answers found, let GPT-4o answer with strict instructions
    if (!foundAnswers) {
      console.info('[RAG] No matches found in knowledge base');
      console.info('[RAG] Using GPT-4o to generate answer from general knowledge...');
      
      const gptPrompt = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ××ª×” ××“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ ×•××©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—× ×•××™×©×™.

${context.length === 0 ? '×”×ª×—×œ ××ª ×”×ª×©×•×‘×” ×‘××™×œ×™×: "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ğŸ˜Š"' : '×”××©×š ××ª ×”×©×™×—×” ×‘××•×¤×Ÿ ×˜×‘×¢×™, ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×©×•×‘.'}

×—×©×•×‘ ×××•×“:
- ×œ× × ××¦× ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ ×©×œ× ×• ×œ×’×‘×™ ×”×©××œ×”
- ××œ ×ª××¦×™× × ×ª×•× ×™× ××• ××¡×¤×¨×™× ×¡×¤×¦×™×¤×™×™×
- ×¢× ×” ×‘×¦×•×¨×” ×›×œ×œ×™×ª ×‘×œ×‘×“ ×¢×œ ×¡××š ×”×™×“×¢ ×”×‘×¡×™×¡×™ ×¢×œ ×‘×™×˜×•×— ×“×™×¨×•×ª
- ×× ××™× ×š ×‘×˜×•×—, ×××•×¨ "××¦×˜×¨×š ×œ×‘×“×•×§ ××ª ×”×¤×¨×˜×™× ×”××“×•×™×§×™×"
- ×”×™×× ×¢ ×××ª×Ÿ ××—×™×¨×™×, ××—×•×–×™× ××• × ×ª×•× ×™× ×¡×¤×¦×™×¤×™×™×

×”×©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×:
- ×”×“×’×© ××ª ×”×™×ª×¨×•× ×•×ª ×•×”×›×™×¡×•×™×™× ×ª×•×š ×”×¤×’× ×ª ××›×¤×ª×™×•×ª
- ×”×©×ª××© ×‘×©×¤×” ××©×›× ×¢×ª ××š × ×¢×™××” ×•××›×‘×“×ª
- ×”×¦×’ ××ª ×¢×¦××š ×›××•××—×” ×©×“×•××’ ×‘×××ª ×œ×‘×™×˜×—×•×Ÿ ×”×œ×§×•×—
- ×”×©×ª××© ×‘×©×¤×” ××™×©×™×ª ×•×—××”
- ×”×“×’×© ××ª ×”×¢×¨×š ×•×”×‘×™×˜×—×•×Ÿ ×©×”×œ×§×•×— ××§×‘×œ ("×”×©×§×¢×” ×§×˜× ×” ×”×™×•× ×ª×—×¡×•×š ×œ×š ×“××’×•×ª ×¨×‘×•×ª")
- ×”×™×× ×¢ ××—×–×¨×” ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™
- ×”×©×ª××© ×‘××™××•×’'×™ ×‘××§×•××•×ª ××ª××™××™× ×‘×œ×‘×“ (ğŸ˜Š ×œ×—×™×–×•×§ ×—×™×•×‘×™, ğŸ‘ ×œ××™×©×•×¨)
- ×‘×¡×•×£ ×”×ª×©×•×‘×”, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×× ××ª××™× ("×”×× ×ª×¨×¦×” ×©××›×™×Ÿ ×œ×š ×”×¦×¢×ª ××—×™×¨ ××•×ª×××ª?")

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}

×× × ×ª×Ÿ ×ª×©×•×‘×” ×›×œ×œ×™×ª ×•××§×¦×•×¢×™×ª, ×œ×œ× × ×ª×•× ×™× ×¡×¤×¦×™×¤×™×™×.`;

      const messages = [
        { role: 'system', content: gptPrompt },
        { role: 'user', content: '×¢× ×” ×¢×œ ×”×©××œ×” ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª ×•××§×™×¤×”.' }
      ].filter(m => m && typeof m === 'object' && m.content);

      const response = await withTimeout(llm.invoke(messages), 20000);
      
      return response.content.trim();
    }

    // Merge answers with GPT-4o
    const systemPromptForMerge = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ××ª×” ××“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ ×•××©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×.

${context.length === 0 ? '×”×ª×—×œ ××ª ×”×ª×©×•×‘×” ×‘××™×œ×™×: "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ğŸ˜Š"' : '×”××©×š ××ª ×”×©×™×—×” ×‘××•×¤×Ÿ ×˜×‘×¢×™, ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×©×•×‘.'}

×”×©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×:
- ×”×“×’×© ××ª ×”×™×ª×¨×•× ×•×ª ×•×”×›×™×¡×•×™×™× ×ª×•×š ×”×¤×’× ×ª ××›×¤×ª×™×•×ª
- ×”×©×ª××© ×‘×©×¤×” ××©×›× ×¢×ª ××š × ×¢×™××” ×•××›×‘×“×ª
- ×”×¦×’ ××ª ×¢×¦××š ×›××•××—×” ×©×“×•××’ ×‘×××ª ×œ×‘×™×˜×—×•×Ÿ ×”×œ×§×•×—
- ×”×©×ª××© ×‘×©×¤×” ××™×©×™×ª ×•×—××”
- ×”×“×’×© ××ª ×”×¢×¨×š ×•×”×‘×™×˜×—×•×Ÿ ×©×”×œ×§×•×— ××§×‘×œ ("×”×©×§×¢×” ×§×˜× ×” ×”×™×•× ×ª×—×¡×•×š ×œ×š ×“××’×•×ª ×¨×‘×•×ª")
- ×”×™×× ×¢ ××—×–×¨×” ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™
- ×”×©×ª××© ×‘××™××•×’'×™ ×‘××§×•××•×ª ××ª××™××™× ×‘×œ×‘×“ (ğŸ˜Š ×œ×—×™×–×•×§ ×—×™×•×‘×™, ğŸ‘ ×œ××™×©×•×¨)
- ×‘×¡×•×£ ×”×ª×©×•×‘×”, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×× ××ª××™× ("×”×× ×ª×¨×¦×” ×©××›×™×Ÿ ×œ×š ×”×¦×¢×ª ××—×™×¨ ××•×ª×××ª?")

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}

× ××¦××• ×ª×©×•×‘×•×ª ×¨×œ×•×•× ×˜×™×•×ª ×‘×××’×¨. ×©×œ×‘ ××•×ª×Ÿ ×œ×ª×©×•×‘×” ××§×™×¤×” ×ª×•×š ×©×™××•×© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—× ×•×§×¨×™××” ×œ×¤×¢×•×œ×” ×‘×¡×•×£.`;

    const mergedAnswer = await mergeAnswersWithGPTWithContext(answerGroups, question, systemPromptForMerge);
    
    console.info('[RAG] Smart answer generated');
    console.debug('[RAG] Response path:', foundAnswers ? 'langchain' : 'fallback');
    return mergedAnswer;
    
  } catch (error) {
    console.error('[RAG] Error in smartAnswer:', error);
    throw error;
  }
}

/**
 * Merge answers with GPT-4o using custom system prompt
 * @param {Array} answerGroups - Array of {question, answers} objects
 * @param {string} originalQuestion - Original user question
 * @param {string} systemPrompt - System prompt with context
 * @returns {Promise<string>} Merged answer
 */
async function mergeAnswersWithGPTWithContext(answerGroups, originalQuestion, systemPrompt) {
  let contextBlock = '';
  let hasAnswers = false;
  
  for (const group of answerGroups) {
    if (group.answers && group.answers.length > 0) {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™:\n${group.answers.join('\n')}\n`;
      hasAnswers = true;
    } else {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™: ××™×Ÿ ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ - ×™×© ×œ×¢× ×•×ª ××”×™×“×¢ ×”×›×œ×œ×™\n`;
    }
  }

  const userPrompt = hasAnswers 
    ? `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n××™×“×¢ ×©× ××¦× ×‘×××’×¨:\n${contextBlock}\n\n×× × ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×•××§×¦×•×¢×™×ª ×œ×©××œ×ª ×”×œ×§×•×—.`
    : `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n×œ× × ××¦× ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ ×©×œ× ×•. ×× × ×¢× ×” ××”×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª ×•××§×™×¤×”.`;

  const messages = [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt }
  ].filter(m => m && typeof m === 'object' && m.content);

  try {
    const response = await withTimeout(llm.invoke(messages), 20000);
    return response.content.trim();
  } catch (error) {
    console.error('[LangChain] Error merging answers with GPT:', error);
    throw error;
  }
} 