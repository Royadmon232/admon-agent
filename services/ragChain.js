import { createRetrievalChain } from 'langchain/chains/retrieval';
import { createStuffDocumentsChain } from 'langchain/chains/combine_documents';
import { ChatOpenAI, OpenAIEmbeddings } from '@langchain/openai';
import { PGVectorStore } from '@langchain/community/vectorstores/pgvector';
import { PromptTemplate, ChatPromptTemplate, MessagesPlaceholder } from '@langchain/core/prompts';
import { HumanMessage, AIMessage } from '@langchain/core/messages';
import pg from 'pg';
import 'dotenv/config';
import kbConfig from '../src/insuranceKbConfig.js';
import { normalize } from '../utils/normalize.js';
import { readFileSync } from 'fs';
import { fileURLToPath } from 'url';
import { dirname, join, resolve } from 'path';

// Load sales templates
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);
const templatesPath = join(process.cwd(), 'marketing_templates.json');

console.info(`[RAG] Loading templates from: ${templatesPath}`);

let salesTemplates;
try {
  salesTemplates = JSON.parse(readFileSync(templatesPath, 'utf8'));
  console.info('[RAG] Successfully loaded marketing templates');
} catch (error) {
  console.error('[RAG] Error loading marketing templates:', error.message);
  // Fallback to default templates if file not found
  salesTemplates = {
    LEAD: [
      "×‘×™×˜×•×— ×“×™×¨×” ××’×Ÿ ×¢×œ ×”×”×©×§×¢×” ×”×›×™ ×—×©×•×‘×” ×©×œ×š ××¤× ×™ × ×–×§×™ ××™×, ×’× ×™×‘×” ×•××©",
      "×¤×•×œ×™×¡×ª ×‘×™×˜×•×— ×“×™×¨×” ××™×›×•×ª×™×ª ×™×›×•×œ×” ×œ×—×¡×•×š ×œ×š ×¢×©×¨×•×ª ××œ×¤×™ ×©×§×œ×™× ×‘×¢×ª × ×–×§"
    ],
    DEFAULT: [
      "×× ×™ ×›××Ÿ ×œ×¢×–×•×¨ ×œ×š ×œ×”×‘×™×Ÿ ××ª ×”××¤×©×¨×•×™×•×ª ×”×©×•× ×•×ª ×œ×‘×™×˜×•×— ×“×™×¨×”",
      "×›×œ ××§×¨×” ×”×•× ×™×™×—×•×“×™ ×•×× ×™ ××ª××™× ××ª ×”×”××œ×¦×•×ª ×œ×¦×¨×›×™× ×©×œ×š"
    ]
  };
  console.info('[RAG] Using fallback templates');
}

console.info("âœ… PromptTemplate loaded correctly");

// Initialize PostgreSQL pool - prioritize DATABASE_URL for external connections
const pool = new pg.Pool({ 
  connectionString: process.env.DATABASE_URL,
  ssl: {
    rejectUnauthorized: false
  }
});

// Log successful connection
pool.on('connect', () => {
  console.info('âœ… LangChain DB connection established using external DATABASE_URL with SSL');
});

// Initialize OpenAI components
const embeddings = new OpenAIEmbeddings({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: 'text-embedding-ada-002'
});

const llm = new ChatOpenAI({
  openAIApiKey: process.env.OPENAI_API_KEY,
  modelName: 'gpt-4o',
  temperature: 0.7
});

let vectorStore = null;
let chain = null;

// Initialize the RAG chain
export async function initializeChain() {
  try {
    // Initialize PGVector store using external DATABASE_URL
    // Note: Using pure vector similarity search without metadata filtering
    vectorStore = await PGVectorStore.initialize(
      embeddings,
      {
        postgresConnectionOptions: {
          connectionString: process.env.DATABASE_URL,
          ssl: { rejectUnauthorized: false }
        },
        tableName: kbConfig.tableName,
        columns: {
          idColumnName: kbConfig.idColumnName ?? 'id',
          vectorColumnName: kbConfig.embeddingColumnName,
          contentColumnName: kbConfig.contentColumnName,
          metadataColumnName: null // Explicitly disable metadata
        },
        filter: {}, // Force embedding-only search with empty filter
        distanceStrategy: 'cosine' // Use cosine similarity for vector comparison
      }
    );

    // Create modern prompt template with anti-hallucination
    const chatPrompt = ChatPromptTemplate.fromTemplate(`
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ.

×”× ×—×™×•×ª ×œ×˜×•×Ÿ ×•×©×¤×”:
- ×¤× ×” ×œ×œ×§×•×— ×‘×©××• ×”×¤×¨×˜×™ ×›×©×™×“×•×¢ ("{{name}}, ××©××— ×œ×”×¡×‘×™×¨...")
- ×”×©×ª××© ×‘×œ×©×•×Ÿ ×—××”, ××™×©×™×ª ×•××–××™× ×” ×ª×•×š ×©××™×¨×” ×¢×œ ××§×¦×•×¢×™×•×ª
- ×”×¤×’×Ÿ ×××¤×ª×™×” ×•×“××’×” ×›× ×” ("×× ×™ ××‘×™×Ÿ ××ª ×”×—×©×©×•×ª ×©×œ×š, ×–×” ×˜×‘×¢×™...")
- ×”×©×ª××© ×‘×‘×™×˜×•×™×™× ××¢×•×“×“×™× ×•×—×™×•×‘×™×™×
- ×¤× ×” ×œ×œ×§×•×— ×‘×’×•×£ ×©× ×™ × ×•×›×— (××ª/×”)
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™

×”× ×—×™×•×ª ×—×©×•×‘×•×ª:
- ×”×©×ª××© ××š ×•×¨×§ ×‘××™×“×¢ ×”××•×¤×™×¢ ×‘×”×§×©×¨ ×œ××˜×”
- ××œ ×ª××¦×™× ××• ×ª× ×—×© × ×ª×•× ×™× ×©××™× × ××•×¤×™×¢×™× ×‘××¤×•×¨×©
- ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢, ×××•×¨ "××‘×“×•×§ ××ª ×”× ×•×©× ×•××—×–×•×¨ ××œ×™×š"
- ××œ ×ª×¢× ×” ×¢×œ ×©××œ×•×ª ×©××™× ×Ÿ ×§×©×•×¨×•×ª ×œ×‘×™×˜×•×— ×“×™×¨×”

×”×§×©×¨ (××™×“×¢ ××”×××’×¨):
{context}

×©××œ×”: {input}

×ª×Ÿ ×ª×©×•×‘×” ××§×¦×•×¢×™×ª, ×™×“×™×“×•×ª×™×ª ×•××§×™×¤×” ×‘×¢×‘×¨×™×ª ×”××‘×•×¡×¡×ª ×¢×œ ×”××™×“×¢ ×‘×”×§×©×¨ ×‘×œ×‘×“.
×× ×”××™×“×¢ ×‘×”×§×©×¨ ×œ× ××¡×¤×™×§, ×××•×¨ ×–××ª ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª.
×‘×¡×•×£ ×”×ª×©×•×‘×”, ×× ××ª××™×, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×—××” ×•××–××™× ×”.
`);

    // Create document chain
    const documentChain = await createStuffDocumentsChain({
      llm,
      prompt: chatPrompt
    });

    // Create the conversational retrieval chain
    chain = await createRetrievalChain({
      combineDocsChain: documentChain,
      retriever: vectorStore.asRetriever({
        k: 8,
        searchType: 'similarity',
        searchKwargs: {
          scoreThreshold: 0.70
        }
      })
    });

    console.log('âœ… LangChain RAG chain initialized successfully');
  } catch (error) {
    console.error('âš ï¸ Failed to initialize LangChain RAG chain:', error.message);
    chain = null;
  }
}

// Initialize on module load
// initializeChain(); // Commented out - now called from index.js

// Ensure the vector store table has the required columns
(async () => {
  try {
    await pool.query(`
      DO $$ 
      BEGIN
        -- Add metadata column if it doesn't exist
        IF NOT EXISTS (
          SELECT 1 
          FROM information_schema.columns 
          WHERE table_name = '${kbConfig.tableName}' 
          AND column_name = 'metadata'
        ) THEN
          ALTER TABLE ${kbConfig.tableName} 
          ADD COLUMN metadata JSONB DEFAULT '{}'::jsonb;
        END IF;
      END $$;
    `);
    console.log('âœ… Vector store table structure verified');
  } catch (err) {
    console.error('âš ï¸ Failed to verify vector store table structure:', err.message);
  }
})();

/**
 * Split questions if multiple questions are detected
 * @param {string} text - User input text
 * @returns {string[]} Array of individual questions
 */
function splitQuestions(text) {
  // Split by question marks, periods followed by capital letters, or common Hebrew question patterns
  const patterns = [
    /\?/g,
    /\./g,
    /\n/g,
    /×•(?=××”|××™×š|×›××”|××ª×™|××™×¤×”|×œ××”|×”××)/g // Hebrew 'and' before question words
  ];
  
  let questions = [text];
  
  for (const pattern of patterns) {
    const newQuestions = [];
    for (const q of questions) {
      const splits = q.split(pattern).map(s => s.trim()).filter(s => s.length > 5);
      if (splits.length > 1) {
        newQuestions.push(...splits);
      } else {
        newQuestions.push(q);
      }
    }
    questions = newQuestions;
  }
  
  // Remove duplicates and empty strings
  return [...new Set(questions.filter(q => q && q.trim().length > 5))];
}

/**
 * Merge answers with GPT-4o for natural, marketing-oriented Hebrew response
 * @param {Array} answerGroups - Array of {question, answers} objects
 * @param {string} originalQuestion - Original user question
 * @param {string} historyContext - Conversation history context
 * @returns {Promise<string>} Merged answer
 */
async function mergeAnswersWithGPT(answerGroups, originalQuestion, historyContext = '') {
  const systemPrompt = `××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ. ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ××§×¦×•×¢×™ ×•××“×™×‘. ×ª×¤×§×™×“×š ×œ×¢× ×•×ª ×¢×œ ×©××œ×•×ª ×‘× ×•×©× ×‘×™×˜×•×— ×“×™×¨×” ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª, ×™×“×™×“×•×ª×™×ª ×•××§×™×¤×”.

×›×œ ×ª×©×•×‘×” ×©×œ×š ×—×™×™×‘×ª:
  1. ×œ×”×™×•×ª ×‘×¢×‘×¨×™×ª ×ª×§×™× ×” ×•××§×¦×•×¢×™×ª
  2. ×œ×”×™×•×ª ×× ×•×¡×—×ª ×‘×¦×•×¨×” ×™×“×™×“×•×ª×™×ª, ××›×‘×“×ª ×•×‘×˜×•×Ÿ ××™×©×™ ×•× ×¢×™×
  3. ×œ×”×ª×™×™×—×¡ ×™×©×™×¨×•×ª ×œ×©××œ×” ×©× ×©××œ×”
  4. ×œ×›×œ×•×œ ××ª ×›×œ ×”××™×“×¢ ×”×¨×œ×•×•× ×˜×™ ×•×”×—×©×•×‘
  5. ×œ×”×™×•×ª ××“×•×™×§×ª ××‘×—×™× ×” ××§×¦×•×¢×™×ª

×§×™×‘×œ×ª ××™×“×¢ ×¨×œ×•×•× ×˜×™ ××”×××’×¨ ×©×œ× ×•. ×¢×œ×™×š:
  1. ×œ×©×œ×‘ ××ª ×”××™×“×¢ ×”×¨×œ×•×•× ×˜×™ ×‘×ª×©×•×‘×” ××—×ª ××§×™×¤×” ×•×§×•×”×¨× ×˜×™×ª
  2. ×œ× ×¡×— ×‘×¡×’× ×•×Ÿ ××™×©×™ ×•×™×™×—×•×“×™ ××©×œ×š, ×©×ª×¨×’×™×© ××•×ª× ×˜×™×ª ×•×˜×‘×¢×™×ª ×œ×œ×§×•×—
  3. ×× ××™×Ÿ ××¡×¤×™×§ ××™×“×¢ ×œ×—×œ×§ ××”×©××œ×”, ×”×©×œ× ××”×™×“×¢ ×©×œ×š
  4. ×œ×•×•×“× ×©×”×ª×©×•×‘×” ×©×œ××” ×•××©×“×¨×ª ×‘×™×˜×—×•×Ÿ ×•××§×¦×•×¢×™×•×ª`;

  let contextBlock = '';
  for (const group of answerGroups) {
    if (group.answers && group.answers.length > 0) {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™:\n${group.answers.join('\n')}\n`;
    } else {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™: ××™×Ÿ ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ - ×™×© ×œ×¢× ×•×ª ××”×™×“×¢ ×”×›×œ×œ×™\n`;
    }
  }

  const userPrompt = `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n××™×“×¢ ×©× ××¦× ×‘×××’×¨:\n${contextBlock}\n\n${historyContext}\n\n×× × ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×•××§×¦×•×¢×™×ª ×œ×©××œ×ª ×”×œ×§×•×—.`;

  try {
    const response = await llm.invoke([
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt }
    ]);
    
    return response.content.trim();
  } catch (error) {
    console.error('[LangChain] Error merging answers with GPT:', error);
    throw error;
  }
}

/**
 * Detect if a question is a follow-up to the previous conversation
 * @param {string} text - User question
 * @param {Array} history - Conversation history
 * @returns {Promise<boolean>} True if it's a follow-up question
 */
async function isFollowUpQuestion(text, history) {
  if (!history || history.length === 0) return false;
  
  // Common Hebrew follow-up patterns
  const followUpPatterns = [
    /^(×ª×•×›×œ|×™×›×•×œ|××¤×©×¨) ×œ×”×¡×‘×™×¨/i,
    /^××” (×–××ª ××•××¨×ª|×”×›×•×•× ×”)/i,
    /^(×¢×•×“|×™×•×ª×¨) (×¤×¨×˜×™×|××™×“×¢|×”×¡×‘×¨)/i,
    /^(×œ×|×›×Ÿ),? ××‘×œ/i,
    /^×•(××”|××™×š|×›××”|××ª×™|××™×¤×”|×œ××”)/i,
    /^×‘× ×•×¡×£/i,
    /^×’×/i,
    /^××–/i,
    /^×œ××”/i,
    /^××™×š ×‘×“×™×•×§/i,
    /^×ª×Ÿ ×œ×™ ×“×•×’××”/i,
    /^×”×¡×‘×¨/i,
    /^×¤×¨×˜/i
  ];
  
  // Check if the question matches follow-up patterns
  const normalized = text.trim();
  return followUpPatterns.some(pattern => pattern.test(normalized));
}

/**
 * Get smart answer using LangChain RAG
 * @param {string} question - User question
 * @param {Array} context - Array of conversation history objects with user/bot properties
 * @returns {Promise<string|null>} Answer or null if not available
 */
export async function smartAnswer(question, context = []) {
  if (!vectorStore) {
    console.warn('[LangChain] Vector store not initialized, skipping');
    return null;
  }

  console.debug('[RAG] Normalized question:', question);
  console.debug('[RAG] Using column:', kbConfig.embeddingColumnName);
  console.debug('[RAG] Context length:', context.length);

  // Check for greetings first - only if this is the first message
  if (context.length === 0 && /^(×”×™×™|×©×œ×•×|×¦×”×¨×™×™×|×¢×¨×‘ ×˜×•×‘)/i.test(question.trim())) {
    console.debug('[RAG] Detected greeting - returning standard response');
    return "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ××™×š ××•×›×œ ×œ×¢×–×•×¨?";
  }

  // Check if question is out of scope
  const insuranceKeywords = ['×‘×™×˜×•×—', '×¤×•×œ×™×¡×”', '×›×™×¡×•×™', '×“×™×¨×”', '× ×–×§', '×ª×‘×™×¢×”', '×¤×¨××™×”', '×”×©×ª×ª×¤×•×ª'];
  const hasInsuranceContext = insuranceKeywords.some(keyword => question.includes(keyword));

  // If the message is clearly unrelated to insurance (small-talk, chit-chat, etc.) and there is no prior context,
  // let GPT-4o answer naturally instead of refusing.
  if (!hasInsuranceContext && context.length === 0) {
    console.info('[RAG] Detected small-talk / out-of-domain question â€“ using GPT-4o friendly fallback');

    const messages = [
      {
        role: 'system',
        content: `××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ×“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ ×‘×˜×•×Ÿ ×—×, ×× ×•×©×™ ×•××–××™×Ÿ. ×¢× ×” ×¢×œ ×©××œ×•×ª ×›×œ×œ×™×•×ª small-talk ×‘×¦×•×¨×” × ×¢×™××” ×•××§×¦×•×¢×™×ª, ×œ×œ× ××–×›×•×¨ ×©××ª×” ×‘×•×˜ ××• AI.`
      },
      { role: 'user', content: question }
    ];

    try {
      const response = await llm.call(messages);
      return response.content.trim();
    } catch (err) {
      console.error('[RAG] GPT-4o fallback error:', err);
      // In worst-case, still provide graceful reply
      return '×”×›×œ ××¦×•×™×Ÿ, ×ª×•×“×” ×¢×œ ×”×”×ª×¢× ×™×™× ×•×ª! ××™×š ××•×›×œ ×œ×¢×–×•×¨ ×œ×š ×‘× ×•×©× ×‘×™×˜×•×— ×”×“×™×¨×”? ğŸ˜Š';
    }
  }

  try {
    // Build conversation history for prompt
    const conversationHistory = context.map(msg => `User: ${msg.user}\nBot: ${msg.bot}`).join('\n');
    
    // Check if this is a follow-up question using GPT-4o
    const contextCheckPrompt = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™.
×”×©×ª××© ×‘×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×” ×”×‘××” ×›×“×™ ×œ×§×‘×•×¢ ×× ×”×©××œ×” ×”× ×•×›×—×™×ª ×”×™× ×”××©×š ×œ×©×™×—×” ×§×•×“××ª.
×× ×”××©×ª××© ×©×•××œ ×©××œ×ª ×”××©×š (×œ××©×œ "×ª×¡×‘×™×¨ ×©×•×‘"), ×¢× ×” ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×§×©×¨ ×”×§×•×“×.
×× ×”××©×ª××© ×©×•××œ ××©×”×• ×—×“×©, ×”×ª×¢×œ× ××”×§×©×¨ ×•×”×¤×¢×œ ×—×™×¤×•×© ×•×§×˜×•×¨×™ ×›×¨×’×™×œ.

×—×©×•×‘:
- ××œ ×ª×—×–×•×¨ ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×©×•×‘ ×× ×›×‘×¨ ×”×¦×’×ª ××ª ×¢×¦××š
- ×”×©×ª××© ×‘×©×¤×” ×˜×‘×¢×™×ª, ×—××” ×•××§×¦×•×¢×™×ª
- ×“×‘×¨ ×‘×’×•×£ ×¨××©×•×Ÿ
- ×¤× ×” ×œ×œ×§×•×— ×‘×©××• ×× ×™×“×•×¢
- ×”×¤×’×Ÿ ×××¤×ª×™×” ×•×“××’×”
- ×”×™×× ×¢ ××œ×•××¨ ×©××ª×” ×‘×•×˜ ××• AI

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}
`;

    // First, check if this is a follow-up question
    const isFollowUp = await isFollowUpQuestion(question, context);
    
    if (isFollowUp && context.length > 0) {
      // Follow-up detected - answer directly using context only
      console.info('[RAG] Follow-up question detected, using context only');
      
      const messages = [
        { role: 'system', content: contextCheckPrompt },
        { role: 'user', content: '×¢× ×” ×¢×œ ×”×©××œ×” ×”× ×•×›×—×™×ª ×‘×”×ª×‘×¡×¡ ×¢×œ ×”×”×™×¡×˜×•×¨×™×”. ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×‘×¢×‘×¨×™×ª.' }
      ].filter(m => m && typeof m === 'object' && m.content);

      const response = await llm.call(messages);
      
      console.debug('[RAG] Generated follow-up response');
      return response.content.trim();
    }

    // Not a clear follow-up, proceed with vector search
    console.info('[RAG] Running vector search...');
    
    // Split questions if multiple detected
    const questions = splitQuestions(question);
    console.info(`[RAG] Processing ${questions.length} question(s)`);

    // Process each question with timeout protection
    let answerGroups = [];
    let foundAnswers = false;
    
    for (const q of questions) {
      try {
        const query = normalize(q);
        // First attempt with higher threshold (was 0.70, now 0.75)
        let results = await vectorStore.similaritySearchWithScore(
          normalize(q),
          15,
          { scoreThreshold: 0.75 }
        );
        
        // If no results or low scores, try second attempt with lower threshold (was 0.60, now 0.65)
        if (results.length === 0 || results[0][1] > 0.25) {
          console.debug('[RAG] First attempt failed, trying with lower threshold...');
          results = await vectorStore.similaritySearchWithScore(
            normalize(q),
            15,
            { scoreThreshold: 0.65 }
          );
        }
        
        // If still no results, mark as no match
        if (results.length === 0) {
          console.info('[RAG] No matches found even with lower threshold');
          continue;
        }
        
        // Log raw scores for debugging
        console.debug(`[RAG] Raw scores for "${q}":`, results.map(([doc, score]) => score.toFixed(4)));
        
        // Clean and filter answers
        const answers = results
          .map(([doc, score]) => {
            const content = doc.pageContent || doc.content || '';
            // Remove non-informative phrases
            const cleaned = content
              .replace(/×œ××™×“×¢ × ×•×¡×£ ×¦×•×¨ ×§×©×¨/g, '')
              .replace(/×œ×¤×¨×˜×™× × ×•×¡×¤×™×/g, '')
              .replace(/\s{2,}/g, ' ')
              .trim();
            
            if (cleaned.length < 20) return null; // Too short to be useful
            
            console.debug(`[RAG] Match found - similarity: ${(1 - score).toFixed(4)}, content: ${cleaned.slice(0, 50)}...`);
            return cleaned;
          })
          .filter(answer => answer && answer.trim().length > 0);
        
        if (answers.length > 0) {
          foundAnswers = true;
          console.debug(`[RAG] Found ${answers.length} matches for question: ${q}`);
        } else {
          console.debug(`[RAG] No useful matches found for question: ${q}`);
        }
        
        answerGroups.push({
          question: q,
          answers: answers
        });
      } catch (error) {
        console.error(`[RAG] Error processing question "${q}":`, error);
        answerGroups.push({
          question: q,
          answers: []
        });
      }
    }

    // If no answers found, let GPT-4o answer with strict instructions
    if (!foundAnswers) {
      console.info('[RAG] No matches found, using GPT-4o with strict instructions...');
      
      const gptPrompt = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ××ª×” ××“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ ×•××©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—× ×•××™×©×™.

${context.length === 0 ? '×”×ª×—×œ ××ª ×”×ª×©×•×‘×” ×‘××™×œ×™×: "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ğŸ˜Š"' : '×”××©×š ××ª ×”×©×™×—×” ×‘××•×¤×Ÿ ×˜×‘×¢×™, ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×©×•×‘.'}

×—×©×•×‘ ×××•×“:
- ×œ× × ××¦× ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ ×©×œ× ×• ×œ×’×‘×™ ×”×©××œ×”
- ××œ ×ª××¦×™× × ×ª×•× ×™× ××• ××¡×¤×¨×™× ×¡×¤×¦×™×¤×™×™×
- ×¢× ×” ×‘×¦×•×¨×” ×›×œ×œ×™×ª ×‘×œ×‘×“ ×¢×œ ×¡××š ×”×™×“×¢ ×”×‘×¡×™×¡×™ ×¢×œ ×‘×™×˜×•×— ×“×™×¨×•×ª
- ×× ××™× ×š ×‘×˜×•×—, ×××•×¨ "××¦×˜×¨×š ×œ×‘×“×•×§ ××ª ×”×¤×¨×˜×™× ×”××“×•×™×§×™×"
- ×”×™×× ×¢ ×××ª×Ÿ ××—×™×¨×™×, ××—×•×–×™× ××• × ×ª×•× ×™× ×¡×¤×¦×™×¤×™×™×

×”×©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×:
- ×”×“×’×© ××ª ×”×™×ª×¨×•× ×•×ª ×•×”×›×™×¡×•×™×™× ×ª×•×š ×”×¤×’× ×ª ××›×¤×ª×™×•×ª
- ×”×©×ª××© ×‘×©×¤×” ××©×›× ×¢×ª ××š × ×¢×™××” ×•××›×‘×“×ª
- ×”×¦×’ ××ª ×¢×¦××š ×›××•××—×” ×©×“×•××’ ×‘×××ª ×œ×‘×™×˜×—×•×Ÿ ×”×œ×§×•×—
- ×”×©×ª××© ×‘×©×¤×” ××™×©×™×ª ×•×—××”
- ×”×“×’×© ××ª ×”×¢×¨×š ×•×”×‘×™×˜×—×•×Ÿ ×©×”×œ×§×•×— ××§×‘×œ ("×”×©×§×¢×” ×§×˜× ×” ×”×™×•× ×ª×—×¡×•×š ×œ×š ×“××’×•×ª ×¨×‘×•×ª")
- ×”×™×× ×¢ ××—×–×¨×” ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™
- ×”×©×ª××© ×‘××™××•×’'×™ ×‘××§×•××•×ª ××ª××™××™× ×‘×œ×‘×“ (ğŸ˜Š ×œ×—×™×–×•×§ ×—×™×•×‘×™, ğŸ‘ ×œ××™×©×•×¨)
- ×‘×¡×•×£ ×”×ª×©×•×‘×”, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×× ××ª××™× ("×”×× ×ª×¨×¦×” ×©××›×™×Ÿ ×œ×š ×”×¦×¢×ª ××—×™×¨ ××•×ª×××ª?")

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}

×× × ×ª×Ÿ ×ª×©×•×‘×” ×›×œ×œ×™×ª ×•××§×¦×•×¢×™×ª, ×œ×œ× × ×ª×•× ×™× ×¡×¤×¦×™×¤×™×™×.`;

      const messages = [
        { role: 'system', content: gptPrompt },
        { role: 'user', content: '×¢× ×” ×¢×œ ×”×©××œ×” ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª ×•××§×™×¤×”.' }
      ].filter(m => m && typeof m === 'object' && m.content);

      const response = await llm.invoke(messages);
      
      return response.content.trim();
    }

    // Merge answers with GPT-4o
    const systemPromptForMerge = `
××ª×” ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª ×•×™×¨×˜×•××œ×™ ××§×¦×•×¢×™ ×•××™×©×™. ××ª×” ××“×‘×¨ ×‘×¢×‘×¨×™×ª ×‘×’×•×£ ×¨××©×•×Ÿ ×•××©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×.

${context.length === 0 ? '×”×ª×—×œ ××ª ×”×ª×©×•×‘×” ×‘××™×œ×™×: "×©×œ×•×! ×× ×™ ×“×•× ×™, ×¡×•×›×Ÿ ×‘×™×˜×•×— ×“×™×¨×•×ª. ×©××— ×œ×¢×–×•×¨ ×œ×š ğŸ˜Š"' : '×”××©×š ××ª ×”×©×™×—×” ×‘××•×¤×Ÿ ×˜×‘×¢×™, ×‘×œ×™ ×œ×”×¦×™×’ ××ª ×¢×¦××š ×©×•×‘.'}

×”×©×ª××© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—×:
- ×”×“×’×© ××ª ×”×™×ª×¨×•× ×•×ª ×•×”×›×™×¡×•×™×™× ×ª×•×š ×”×¤×’× ×ª ××›×¤×ª×™×•×ª
- ×”×©×ª××© ×‘×©×¤×” ××©×›× ×¢×ª ××š × ×¢×™××” ×•××›×‘×“×ª
- ×”×¦×’ ××ª ×¢×¦××š ×›××•××—×” ×©×“×•××’ ×‘×××ª ×œ×‘×™×˜×—×•×Ÿ ×”×œ×§×•×—
- ×”×©×ª××© ×‘×©×¤×” ××™×©×™×ª ×•×—××”
- ×”×“×’×© ××ª ×”×¢×¨×š ×•×”×‘×™×˜×—×•×Ÿ ×©×”×œ×§×•×— ××§×‘×œ ("×”×©×§×¢×” ×§×˜× ×” ×”×™×•× ×ª×—×¡×•×š ×œ×š ×“××’×•×ª ×¨×‘×•×ª")
- ×”×™×× ×¢ ××—×–×¨×” ×¢×œ ××™×“×¢ ×©×›×‘×¨ × ×××¨ ×‘×©×™×—×”
- ××œ ×ª×¦×™×’ ××ª ×¢×¦××š ×›×‘×•×˜ ××• AI - ××ª×” ×¡×•×›×Ÿ ×‘×™×˜×•×— ×××™×ª×™
- ×”×©×ª××© ×‘××™××•×’'×™ ×‘××§×•××•×ª ××ª××™××™× ×‘×œ×‘×“ (ğŸ˜Š ×œ×—×™×–×•×§ ×—×™×•×‘×™, ğŸ‘ ×œ××™×©×•×¨)
- ×‘×¡×•×£ ×”×ª×©×•×‘×”, ×”×•×¡×£ ×§×¨×™××” ×œ×¤×¢×•×œ×” ×× ××ª××™× ("×”×× ×ª×¨×¦×” ×©××›×™×Ÿ ×œ×š ×”×¦×¢×ª ××—×™×¨ ××•×ª×××ª?")

×”×™×¡×˜×•×¨×™×™×ª ×”×©×™×—×”:
${conversationHistory}

×©××œ×” × ×•×›×—×™×ª: ${question}

× ××¦××• ×ª×©×•×‘×•×ª ×¨×œ×•×•× ×˜×™×•×ª ×‘×××’×¨. ×©×œ×‘ ××•×ª×Ÿ ×œ×ª×©×•×‘×” ××§×™×¤×” ×ª×•×š ×©×™××•×© ×‘×¡×’× ×•×Ÿ ×©×™×•×•×§×™-×™×™×¢×•×¦×™ ×—× ×•×§×¨×™××” ×œ×¤×¢×•×œ×” ×‘×¡×•×£.`;

    const mergedAnswer = await mergeAnswersWithGPTWithContext(answerGroups, question, systemPromptForMerge);
    
    console.info('[RAG] Smart answer generated');
    console.debug('[RAG] Response path:', foundAnswers ? 'langchain' : 'fallback');
    return mergedAnswer;
    
  } catch (error) {
    console.error('[RAG] Error in smartAnswer:', error);
    throw error;
  }
}

/**
 * Merge answers with GPT-4o using custom system prompt
 * @param {Array} answerGroups - Array of {question, answers} objects
 * @param {string} originalQuestion - Original user question
 * @param {string} systemPrompt - System prompt with context
 * @returns {Promise<string>} Merged answer
 */
async function mergeAnswersWithGPTWithContext(answerGroups, originalQuestion, systemPrompt) {
  let contextBlock = '';
  let hasAnswers = false;
  
  for (const group of answerGroups) {
    if (group.answers && group.answers.length > 0) {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™:\n${group.answers.join('\n')}\n`;
      hasAnswers = true;
    } else {
      contextBlock += `\n×©××œ×”: ${group.question}\n`;
      contextBlock += `××™×“×¢ ×¨×œ×•×•× ×˜×™: ××™×Ÿ ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ - ×™×© ×œ×¢× ×•×ª ××”×™×“×¢ ×”×›×œ×œ×™\n`;
    }
  }

  const userPrompt = hasAnswers 
    ? `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n××™×“×¢ ×©× ××¦× ×‘×××’×¨:\n${contextBlock}\n\n×× × ×ª×Ÿ ×ª×©×•×‘×” ××§×™×¤×” ×•××§×¦×•×¢×™×ª ×œ×©××œ×ª ×”×œ×§×•×—.`
    : `×”×©××œ×” ×”××§×•×¨×™×ª ×©×œ ×”×œ×§×•×—: ${originalQuestion}\n\n×œ× × ××¦× ××™×“×¢ ×¡×¤×¦×™×¤×™ ×‘×××’×¨ ×©×œ× ×•. ×× × ×¢× ×” ××”×™×“×¢ ×”×›×œ×œ×™ ×©×œ×š ×‘×¦×•×¨×” ××§×¦×•×¢×™×ª ×•××§×™×¤×”.`;

  const messages = [
    { role: 'system', content: systemPrompt },
    { role: 'user', content: userPrompt }
  ].filter(m => m && typeof m === 'object' && m.content);

  try {
    const response = await llm.invoke(messages);
    return response.content.trim();
  } catch (error) {
    console.error('[LangChain] Error merging answers with GPT:', error);
    throw error;
  }
} 